{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65bcf23a",
   "metadata": {},
   "source": [
    "# ğŸ“¸ Advanced Image Alignment for Timelapse Creation\n",
    "\n",
    "This notebook demonstrates how to align images taken from the same location over time to create smooth, professional-quality timelapse videos. The algorithm handles camera shake, slight position changes, and lighting variations while preserving original colors.\n",
    "\n",
    "## âœ¨ Features\n",
    "- **Color Preservation**: Maintains original image colors (no grayscale output)\n",
    "- **Robust Alignment**: Uses ORB feature detection with RANSAC for reliable matching\n",
    "- **Smart Cropping**: Applies zoom-in to reduce black borders from alignment\n",
    "- **Batch Processing**: Handles multiple folders automatically\n",
    "- **Error Handling**: Gracefully manages problematic images\n",
    "\n",
    "## ğŸ“ Expected Folder Structure\n",
    "```\n",
    "images/\n",
    "â”œâ”€â”€ location1/\n",
    "â”œâ”€â”€ location2/\n",
    "â”œâ”€â”€ ...\n",
    "```\n",
    "\n",
    "Output will be saved to:\n",
    "```\n",
    "aligned/\n",
    "â”œâ”€â”€ location1/\n",
    "â”œâ”€â”€ location2/\n",
    "â”œâ”€â”€ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26e894",
   "metadata": {},
   "source": [
    "## ğŸ”§ Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f5e421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported and configuration set!\n",
      "ğŸ“ Input directory: images\n",
      "ğŸ“ Output directory: aligned\n",
      "ğŸ” Zoom factor: 1.15x\n",
      "ğŸ¯ Max features: 5000\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ“‚ Directory Configuration\n",
    "input_dir = \"images\"      # Source folder containing subfolders with images\n",
    "output_dir = \"aligned\"    # Output folder for aligned images\n",
    "\n",
    "# âš™ï¸ Processing Parameters\n",
    "zoom_factor = 1.15        # Zoom level (1.0 = no zoom, 1.2 = 20% zoom-in)\n",
    "max_features = 5000       # Number of ORB features to detect\n",
    "min_matches = 10          # Minimum matches required for alignment\n",
    "\n",
    "print(\"âœ… Libraries imported and configuration set!\")\n",
    "print(f\"ğŸ“ Input directory: {input_dir}\")\n",
    "print(f\"ğŸ“ Output directory: {output_dir}\")\n",
    "print(f\"ğŸ” Zoom factor: {zoom_factor}x\")\n",
    "print(f\"ğŸ¯ Max features: {max_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bda638",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Setup and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e07b14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created output directory: aligned\n",
      "ğŸ“‚ Found 4 subfolders: ['AP', 'Elevator', 'JKU', 'Tree']\n",
      "ğŸ› ï¸ Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ Create output directory structure\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"âœ… Created output directory: {output_dir}\")\n",
    "else:\n",
    "    print(f\"ğŸ“ Output directory already exists: {output_dir}\")\n",
    "\n",
    "# ğŸ” Discover subfolders in images directory\n",
    "try:\n",
    "    subfolders = [f for f in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, f))]\n",
    "    print(f\"ğŸ“‚ Found {len(subfolders)} subfolders: {subfolders}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: '{input_dir}' directory not found!\")\n",
    "    subfolders = []\n",
    "\n",
    "def apply_zoom(image, zoom_factor):\n",
    "    \"\"\"\n",
    "    ğŸ” Apply zoom-in effect by cropping the center of the image\n",
    "    \n",
    "    This function reduces black borders created during image alignment\n",
    "    by cropping the center portion and resizing back to original dimensions.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (BGR format)\n",
    "        zoom_factor: Zoom level (1.0 = no zoom, 1.2 = 20% zoom-in)\n",
    "    \n",
    "    Returns:\n",
    "        Zoomed image with same dimensions as input\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Calculate new dimensions after zoom\n",
    "    new_h = int(h / zoom_factor)\n",
    "    new_w = int(w / zoom_factor)\n",
    "\n",
    "    # Calculate crop coordinates (center crop)\n",
    "    start_x = (w - new_w) // 2\n",
    "    start_y = (h - new_h) // 2\n",
    "    end_x = start_x + new_w\n",
    "    end_y = start_y + new_h\n",
    "\n",
    "    # Crop the center portion\n",
    "    cropped = image[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    # Resize back to original dimensions using high-quality interpolation\n",
    "    zoomed = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    return zoomed\n",
    "\n",
    "print(\"ğŸ› ï¸ Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa54b98",
   "metadata": {},
   "source": [
    "## ğŸ–¼ï¸ Image Alignment Processing\n",
    "\n",
    "This section processes each subfolder independently:\n",
    "\n",
    "1. **ğŸ“· Reference Selection**: Uses the first image in each folder as alignment reference\n",
    "2. **ğŸ” Feature Detection**: Extracts ORB features for robust matching\n",
    "3. **ğŸ¯ Feature Matching**: Matches features between reference and target images\n",
    "4. **ğŸ“ Transformation**: Calculates alignment transformation using RANSAC\n",
    "5. **ğŸ¨ Color Preservation**: Applies transformation to color images\n",
    "6. **âœ‚ï¸ Smart Cropping**: Applies zoom to reduce black borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05cd9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ“‚ Processing folder: AP\n",
      "==================================================\n",
      "âœ… Created output subfolder: aligned\\AP\n",
      "ğŸ”¢ Found 26 images to process\n",
      "ğŸ“¸ Reference image: IMG_20250613_133137.jpg\n",
      "ğŸ“ Image dimensions: 3024x4032\n",
      "ğŸ” Features detected in reference: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning AP: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:36<00:00,  1.39s/img]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Folder 'AP' Summary:\n",
      "   âœ… Successfully processed: 26\n",
      "   âš ï¸ Skipped: 0\n",
      "   ğŸ“ˆ Success rate: 100.0%\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Processing folder: Elevator\n",
      "==================================================\n",
      "âœ… Created output subfolder: aligned\\Elevator\n",
      "ğŸ”¢ Found 27 images to process\n",
      "ğŸ“¸ Reference image: IMG_20250618_132349.jpg\n",
      "ğŸ“ Image dimensions: 3024x4032\n",
      "ğŸ” Features detected in reference: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning Elevator: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:58<00:00,  2.17s/img]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Folder 'Elevator' Summary:\n",
      "   âœ… Successfully processed: 27\n",
      "   âš ï¸ Skipped: 0\n",
      "   ğŸ“ˆ Success rate: 100.0%\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Processing folder: JKU\n",
      "==================================================\n",
      "âœ… Created output subfolder: aligned\\JKU\n",
      "ğŸ”¢ Found 29 images to process\n",
      "ğŸ“¸ Reference image: IMG_20250611_132313.jpg\n",
      "ğŸ“ Image dimensions: 3024x4032\n",
      "ğŸ” Features detected in reference: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning JKU: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [01:20<00:00,  2.77s/img]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Folder 'JKU' Summary:\n",
      "   âœ… Successfully processed: 29\n",
      "   âš ï¸ Skipped: 0\n",
      "   ğŸ“ˆ Success rate: 100.0%\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Processing folder: Tree\n",
      "==================================================\n",
      "âœ… Created output subfolder: aligned\\Tree\n",
      "ğŸ”¢ Found 29 images to process\n",
      "ğŸ“¸ Reference image: IMG_20250611_131858.jpg\n",
      "ğŸ“ Image dimensions: 3024x4032\n",
      "ğŸ” Features detected in reference: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning Tree: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [02:43<00:00,  5.64s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Folder 'Tree' Summary:\n",
      "   âœ… Successfully processed: 29\n",
      "   âš ï¸ Skipped: 0\n",
      "   ğŸ“ˆ Success rate: 100.0%\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ PROCESSING COMPLETE!\n",
      "============================================================\n",
      "âœ… Total images processed: 111\n",
      "âš ï¸ Total images skipped: 0\n",
      "ğŸ“ˆ Overall success rate: 100.0%\n",
      "ğŸ” Zoom factor applied: 1.15x\n",
      "ğŸ“ Results saved to: aligned/\n",
      "\n",
      "ğŸ¬ Your aligned images are ready for timelapse creation!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Main Processing Loop\n",
    "total_processed = 0\n",
    "total_skipped = 0\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸ“‚ Processing folder: {subfolder}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # ğŸ“ Setup folder paths\n",
    "    input_folder_path = os.path.join(input_dir, subfolder)\n",
    "    output_folder_path = os.path.join(output_dir, subfolder)\n",
    "    \n",
    "    # ğŸ“ Create output subfolder if needed\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "        print(f\"âœ… Created output subfolder: {output_folder_path}\")\n",
    "    else:\n",
    "        print(f\"ğŸ“ Output subfolder exists: {output_folder_path}\")\n",
    "    \n",
    "    # ğŸ–¼ï¸ Discover image files\n",
    "    image_files = [f for f in os.listdir(input_folder_path) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"âš ï¸ No image files found in {subfolder}\")\n",
    "        continue\n",
    "    \n",
    "    # ğŸ“‹ Sort files for consistent processing order\n",
    "    image_files.sort()\n",
    "    print(f\"ğŸ”¢ Found {len(image_files)} images to process\")\n",
    "    \n",
    "    # ğŸ“· Load reference image (first image in folder)\n",
    "    ref_image_path = os.path.join(input_folder_path, image_files[0])\n",
    "    ref_img_color = cv2.imread(ref_image_path)\n",
    "    \n",
    "    if ref_img_color is None:\n",
    "        print(f\"âŒ Could not read reference image: {ref_image_path}\")\n",
    "        continue\n",
    "        \n",
    "    ref_img_gray = cv2.cvtColor(ref_img_color, cv2.COLOR_BGR2GRAY)\n",
    "    print(f\"ğŸ“¸ Reference image: {image_files[0]}\")\n",
    "    print(f\"ğŸ“ Image dimensions: {ref_img_color.shape[1]}x{ref_img_color.shape[0]}\")\n",
    "\n",
    "    # ğŸ¯ Initialize ORB feature detector\n",
    "    orb = cv2.ORB_create(nfeatures=max_features)\n",
    "    kp1, des1 = orb.detectAndCompute(ref_img_gray, None)\n",
    "    print(f\"ğŸ” Features detected in reference: {len(kp1)}\")\n",
    "\n",
    "    # ğŸ”„ Process each image in the folder\n",
    "    folder_processed = 0\n",
    "    folder_skipped = 0\n",
    "    \n",
    "    for filename in tqdm(image_files, desc=f\"Aligning {subfolder}\", unit=\"img\"):\n",
    "        input_image_path = os.path.join(input_folder_path, filename)\n",
    "        output_image_path = os.path.join(output_folder_path, filename)\n",
    "        \n",
    "        # ğŸ“– Read current image\n",
    "        img_color = cv2.imread(input_image_path)\n",
    "        \n",
    "        if img_color is None:\n",
    "            print(f\"âš ï¸ Could not read {filename}, skipping...\")\n",
    "            folder_skipped += 1\n",
    "            continue\n",
    "            \n",
    "        img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # ğŸ“· Handle reference image (no alignment needed)\n",
    "        if filename == image_files[0]:\n",
    "            zoomed_aligned = apply_zoom(img_color, zoom_factor)\n",
    "            cv2.imwrite(output_image_path, zoomed_aligned)\n",
    "            folder_processed += 1\n",
    "            continue\n",
    "\n",
    "        # ğŸ” Detect features in current image\n",
    "        kp2, des2 = orb.detectAndCompute(img_gray, None)\n",
    "\n",
    "        if des2 is None or len(kp2) < min_matches:\n",
    "            print(f\"âš ï¸ Not enough features in {filename} ({len(kp2) if kp2 else 0} < {min_matches})\")\n",
    "            folder_skipped += 1\n",
    "            continue\n",
    "\n",
    "        # ğŸ¯ Match features between reference and current image\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = matcher.match(des1, des2)\n",
    "\n",
    "        if len(matches) < min_matches:\n",
    "            print(f\"âš ï¸ Not enough matches for {filename} ({len(matches)} < {min_matches})\")\n",
    "            folder_skipped += 1\n",
    "            continue\n",
    "\n",
    "        # ğŸ“Š Select best matches for transformation\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        num_matches = max(20, min(len(matches), int(len(matches) * 0.3)))\n",
    "        good_matches = matches[:num_matches]\n",
    "\n",
    "        # ğŸ“ Extract matched point coordinates\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # ğŸ¯ Calculate robust transformation using RANSAC\n",
    "        try:\n",
    "            M, mask = cv2.estimateAffinePartial2D(\n",
    "                dst_pts, src_pts, \n",
    "                method=cv2.RANSAC,\n",
    "                ransacReprojThreshold=3.0,\n",
    "                maxIters=2000,\n",
    "                confidence=0.99\n",
    "            )\n",
    "\n",
    "            if M is None:\n",
    "                print(f\"âš ï¸ Could not estimate transformation for {filename}\")\n",
    "                folder_skipped += 1\n",
    "                continue\n",
    "\n",
    "            # ğŸ¨ Apply transformation to preserve colors\n",
    "            aligned = cv2.warpAffine(\n",
    "                img_color, M, (ref_img_color.shape[1], ref_img_color.shape[0])\n",
    "            )\n",
    "\n",
    "            # âœ‚ï¸ Apply zoom to reduce black borders\n",
    "            zoomed_aligned = apply_zoom(aligned, zoom_factor)\n",
    "\n",
    "            # ğŸ’¾ Save aligned image\n",
    "            cv2.imwrite(output_image_path, zoomed_aligned)\n",
    "            folder_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {filename}: {e}\")\n",
    "            folder_skipped += 1\n",
    "            continue\n",
    "    \n",
    "    # ğŸ“Š Folder summary\n",
    "    print(f\"\\nğŸ“Š Folder '{subfolder}' Summary:\")\n",
    "    print(f\"   âœ… Successfully processed: {folder_processed}\")\n",
    "    print(f\"   âš ï¸ Skipped: {folder_skipped}\")\n",
    "    print(f\"   ğŸ“ˆ Success rate: {folder_processed/(folder_processed+folder_skipped)*100:.1f}%\")\n",
    "    \n",
    "    total_processed += folder_processed\n",
    "    total_skipped += folder_skipped\n",
    "\n",
    "# ğŸ‰ Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ‰ PROCESSING COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"âœ… Total images processed: {total_processed}\")\n",
    "print(f\"âš ï¸ Total images skipped: {total_skipped}\")\n",
    "print(f\"ğŸ“ˆ Overall success rate: {total_processed/(total_processed+total_skipped)*100:.1f}%\")\n",
    "print(f\"ğŸ” Zoom factor applied: {zoom_factor}x\")\n",
    "print(f\"ğŸ“ Results saved to: {output_dir}/\")\n",
    "print(f\"\\nğŸ¬ Your aligned images are ready for timelapse creation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f97ac",
   "metadata": {},
   "source": [
    "## ğŸ¬ Next Steps: Creating Your Timelapse\n",
    "\n",
    "Now that your images are aligned, you can create professional timelapse videos!\n",
    "\n",
    "### ğŸ› ï¸ Recommended Tools:\n",
    "\n",
    "**FFmpeg (Command Line)**\n",
    "```bash\n",
    "# Create MP4 timelapse at 30 FPS\n",
    "ffmpeg -framerate 30 -pattern_type glob -i \"aligned/AP/*.jpg\" -c:v libx264 -pix_fmt yuv420p timelapse_AP.mp4\n",
    "\n",
    "# Create GIF timelapse\n",
    "ffmpeg -framerate 10 -pattern_type glob -i \"aligned/AP/*.jpg\" -vf \"scale=800:-1\" timelapse_AP.gif\n",
    "```\n",
    "\n",
    "**DaVinci Resolve (Free)**\n",
    "- Import image sequence\n",
    "- Set duration per frame\n",
    "- Add transitions and effects\n",
    "- Export in various formats\n",
    "\n",
    "**Adobe Premiere/After Effects**\n",
    "- Import as image sequence\n",
    "- Adjust frame rate\n",
    "- Add motion blur for smoother playback\n",
    "\n",
    "### âš™ï¸ Tuning Parameters\n",
    "\n",
    "If you need to adjust the alignment quality, modify these parameters in the configuration section:\n",
    "\n",
    "- **`zoom_factor`**: Increase (1.2-1.3) for more aggressive border cropping\n",
    "- **`max_features`**: Increase (7000-10000) for better feature detection\n",
    "- **`min_matches`**: Decrease (5-8) for difficult scenes, increase (15-20) for stricter quality\n",
    "\n",
    "### ğŸ“Š Quality Tips\n",
    "\n",
    "1. **Consistent Lighting**: Take photos at the same time of day\n",
    "2. **Stable Position**: Use a tripod or consistent hand position\n",
    "3. **Regular Intervals**: Consistent time gaps between photos\n",
    "4. **Weather Consideration**: Avoid windy days for outdoor subjects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
