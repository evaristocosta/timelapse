{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65bcf23a",
   "metadata": {},
   "source": [
    "# 📸 Advanced Image Alignment for Timelapse Creation\n",
    "\n",
    "This notebook demonstrates how to align images taken from the same location over time to create smooth, professional-quality timelapse videos. The algorithm handles camera shake, slight position changes, and lighting variations while preserving original colors.\n",
    "\n",
    "## ✨ Features\n",
    "- **Color Preservation**: Maintains original image colors (no grayscale output)\n",
    "- **Robust Alignment**: Uses ORB feature detection with RANSAC for reliable matching\n",
    "- **Smart Cropping**: Applies zoom-in to reduce black borders from alignment\n",
    "- **Batch Processing**: Handles multiple folders automatically\n",
    "- **Error Handling**: Gracefully manages problematic images\n",
    "\n",
    "## 📁 Expected Folder Structure\n",
    "```\n",
    "images/\n",
    "├── location1/\n",
    "├── location2/\n",
    "├── ...\n",
    "```\n",
    "\n",
    "Output will be saved to:\n",
    "```\n",
    "aligned/\n",
    "├── location1/\n",
    "├── location2/\n",
    "├── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26e894",
   "metadata": {},
   "source": [
    "## 🔧 Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 📂 Directory Configuration\n",
    "input_dir = \"images\"      # Source folder containing subfolders with images\n",
    "output_dir = \"aligned\"    # Output folder for aligned images\n",
    "\n",
    "# ⚙️ Processing Parameters\n",
    "zoom_factor = 1.15        # Zoom level (1.0 = no zoom, 1.2 = 20% zoom-in)\n",
    "max_features = 5000       # Number of ORB features to detect\n",
    "min_matches = 10          # Minimum matches required for alignment\n",
    "\n",
    "print(\"✅ Libraries imported and configuration set!\")\n",
    "print(f\"📁 Input directory: {input_dir}\")\n",
    "print(f\"📁 Output directory: {output_dir}\")\n",
    "print(f\"🔍 Zoom factor: {zoom_factor}x\")\n",
    "print(f\"🎯 Max features: {max_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bda638",
   "metadata": {},
   "source": [
    "## 🛠️ Setup and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📁 Create output directory structure\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"✅ Created output directory: {output_dir}\")\n",
    "else:\n",
    "    print(f\"📁 Output directory already exists: {output_dir}\")\n",
    "\n",
    "# 🔍 Discover subfolders in images directory\n",
    "try:\n",
    "    subfolders = [f for f in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, f))]\n",
    "    print(f\"📂 Found {len(subfolders)} subfolders: {subfolders}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: '{input_dir}' directory not found!\")\n",
    "    subfolders = []\n",
    "\n",
    "def apply_zoom(image, zoom_factor):\n",
    "    \"\"\"\n",
    "    🔍 Apply zoom-in effect by cropping the center of the image\n",
    "    \n",
    "    This function reduces black borders created during image alignment\n",
    "    by cropping the center portion and resizing back to original dimensions.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (BGR format)\n",
    "        zoom_factor: Zoom level (1.0 = no zoom, 1.2 = 20% zoom-in)\n",
    "    \n",
    "    Returns:\n",
    "        Zoomed image with same dimensions as input\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Calculate new dimensions after zoom\n",
    "    new_h = int(h / zoom_factor)\n",
    "    new_w = int(w / zoom_factor)\n",
    "\n",
    "    # Calculate crop coordinates (center crop)\n",
    "    start_x = (w - new_w) // 2\n",
    "    start_y = (h - new_h) // 2\n",
    "    end_x = start_x + new_w\n",
    "    end_y = start_y + new_h\n",
    "\n",
    "    # Crop the center portion\n",
    "    cropped = image[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    # Resize back to original dimensions using high-quality interpolation\n",
    "    zoomed = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    return zoomed\n",
    "\n",
    "print(\"🛠️ Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa54b98",
   "metadata": {},
   "source": [
    "## 🖼️ Image Alignment Processing\n",
    "\n",
    "This section processes each subfolder independently:\n",
    "\n",
    "1. **📷 Reference Selection**: Uses the first image in each folder as alignment reference\n",
    "2. **🔍 Feature Detection**: Extracts ORB features for robust matching\n",
    "3. **🎯 Feature Matching**: Matches features between reference and target images\n",
    "4. **📐 Transformation**: Calculates alignment transformation using RANSAC\n",
    "5. **🎨 Color Preservation**: Applies transformation to color images\n",
    "6. **✂️ Smart Cropping**: Applies zoom to reduce black borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cd9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Main Processing Loop\n",
    "total_processed = 0\n",
    "total_skipped = 0\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"📂 Processing folder: {subfolder}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 📁 Setup folder paths\n",
    "    input_folder_path = os.path.join(input_dir, subfolder)\n",
    "    output_folder_path = os.path.join(output_dir, subfolder)\n",
    "    \n",
    "    # 📁 Create output subfolder if needed\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "        print(f\"✅ Created output subfolder: {output_folder_path}\")\n",
    "    else:\n",
    "        print(f\"📁 Output subfolder exists: {output_folder_path}\")\n",
    "    \n",
    "    # 🖼️ Discover image files\n",
    "    image_files = [f for f in os.listdir(input_folder_path) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"⚠️ No image files found in {subfolder}\")\n",
    "        continue\n",
    "    \n",
    "    # 📋 Sort files for consistent processing order\n",
    "    image_files.sort()\n",
    "    print(f\"🔢 Found {len(image_files)} images to process\")\n",
    "    \n",
    "    # 📷 Load reference image (first image in folder)\n",
    "    ref_image_path = os.path.join(input_folder_path, image_files[0])\n",
    "    ref_img_color = cv2.imread(ref_image_path)\n",
    "    \n",
    "    if ref_img_color is None:\n",
    "        print(f\"❌ Could not read reference image: {ref_image_path}\")\n",
    "        continue\n",
    "        \n",
    "    ref_img_gray = cv2.cvtColor(ref_img_color, cv2.COLOR_BGR2GRAY)\n",
    "    print(f\"📸 Reference image: {image_files[0]}\")\n",
    "    print(f\"📐 Image dimensions: {ref_img_color.shape[1]}x{ref_img_color.shape[0]}\")\n",
    "\n",
    "    # 🎯 Initialize ORB feature detector\n",
    "    orb = cv2.ORB_create(nfeatures=max_features)\n",
    "    kp1, des1 = orb.detectAndCompute(ref_img_gray, None)\n",
    "    print(f\"🔍 Features detected in reference: {len(kp1)}\")\n",
    "\n",
    "    # 🔄 Process each image in the folder\n",
    "    folder_processed = 0\n",
    "    folder_skipped = 0\n",
    "    \n",
    "    for filename in tqdm(image_files, desc=f\"Aligning {subfolder}\", unit=\"img\"):\n",
    "        input_image_path = os.path.join(input_folder_path, filename)\n",
    "        output_image_path = os.path.join(output_folder_path, filename)\n",
    "        \n",
    "        # 📖 Read current image\n",
    "        img_color = cv2.imread(input_image_path)\n",
    "        \n",
    "        if img_color is None:\n",
    "            print(f\"⚠️ Could not read {filename}, skipping...\")\n",
    "            folder_skipped += 1\n",
    "            continue\n",
    "            \n",
    "        img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 📷 Handle reference image (no alignment needed)\n",
    "        if filename == image_files[0]:\n",
    "            zoomed_aligned = apply_zoom(img_color, zoom_factor)\n",
    "            cv2.imwrite(output_image_path, zoomed_aligned)\n",
    "            folder_processed += 1\n",
    "            continue\n",
    "\n",
    "        # 🔍 Detect features in current image\n",
    "        kp2, des2 = orb.detectAndCompute(img_gray, None)\n",
    "\n",
    "        if des2 is None or len(kp2) < min_matches:\n",
    "            print(f\"⚠️ Not enough features in {filename} ({len(kp2) if kp2 else 0} < {min_matches})\")\n",
    "            folder_skipped += 1\n",
    "            continue\n",
    "\n",
    "        # 🎯 Match features between reference and current image\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = matcher.match(des1, des2)\n",
    "\n",
    "        if len(matches) < min_matches:\n",
    "            print(f\"⚠️ Not enough matches for {filename} ({len(matches)} < {min_matches})\")\n",
    "            folder_skipped += 1\n",
    "            continue\n",
    "\n",
    "        # 📊 Select best matches for transformation\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        num_matches = max(20, min(len(matches), int(len(matches) * 0.3)))\n",
    "        good_matches = matches[:num_matches]\n",
    "\n",
    "        # 📐 Extract matched point coordinates\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # 🎯 Calculate robust transformation using RANSAC\n",
    "        try:\n",
    "            M, mask = cv2.estimateAffinePartial2D(\n",
    "                dst_pts, src_pts, \n",
    "                method=cv2.RANSAC,\n",
    "                ransacReprojThreshold=3.0,\n",
    "                maxIters=2000,\n",
    "                confidence=0.99\n",
    "            )\n",
    "\n",
    "            if M is None:\n",
    "                print(f\"⚠️ Could not estimate transformation for {filename}\")\n",
    "                folder_skipped += 1\n",
    "                continue\n",
    "\n",
    "            # 🎨 Apply transformation to preserve colors\n",
    "            aligned = cv2.warpAffine(\n",
    "                img_color, M, (ref_img_color.shape[1], ref_img_color.shape[0])\n",
    "            )\n",
    "\n",
    "            # ✂️ Apply zoom to reduce black borders\n",
    "            zoomed_aligned = apply_zoom(aligned, zoom_factor)\n",
    "\n",
    "            # 💾 Save aligned image\n",
    "            cv2.imwrite(output_image_path, zoomed_aligned)\n",
    "            folder_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {filename}: {e}\")\n",
    "            folder_skipped += 1\n",
    "            continue\n",
    "    \n",
    "    # 📊 Folder summary\n",
    "    print(f\"\\n📊 Folder '{subfolder}' Summary:\")\n",
    "    print(f\"   ✅ Successfully processed: {folder_processed}\")\n",
    "    print(f\"   ⚠️ Skipped: {folder_skipped}\")\n",
    "    print(f\"   📈 Success rate: {folder_processed/(folder_processed+folder_skipped)*100:.1f}%\")\n",
    "    \n",
    "    total_processed += folder_processed\n",
    "    total_skipped += folder_skipped\n",
    "\n",
    "# 🎉 Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"🎉 PROCESSING COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"✅ Total images processed: {total_processed}\")\n",
    "print(f\"⚠️ Total images skipped: {total_skipped}\")\n",
    "print(f\"📈 Overall success rate: {total_processed/(total_processed+total_skipped)*100:.1f}%\")\n",
    "print(f\"🔍 Zoom factor applied: {zoom_factor}x\")\n",
    "print(f\"📁 Results saved to: {output_dir}/\")\n",
    "print(f\"\\n🎬 Your aligned images are ready for timelapse creation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f97ac",
   "metadata": {},
   "source": [
    "## 🎬 Next Steps: Creating Your Timelapse\n",
    "\n",
    "Now that your images are aligned, you can create professional timelapse videos!\n",
    "\n",
    "### 🛠️ Recommended Tools:\n",
    "\n",
    "**FFmpeg (Command Line)**\n",
    "```bash\n",
    "# Create MP4 timelapse at 30 FPS\n",
    "ffmpeg -framerate 30 -pattern_type glob -i \"aligned/AP/*.jpg\" -c:v libx264 -pix_fmt yuv420p timelapse_AP.mp4\n",
    "\n",
    "# Create GIF timelapse\n",
    "ffmpeg -framerate 10 -pattern_type glob -i \"aligned/AP/*.jpg\" -vf \"scale=800:-1\" timelapse_AP.gif\n",
    "```\n",
    "\n",
    "**DaVinci Resolve (Free)**\n",
    "- Import image sequence\n",
    "- Set duration per frame\n",
    "- Add transitions and effects\n",
    "- Export in various formats\n",
    "\n",
    "**Adobe Premiere/After Effects**\n",
    "- Import as image sequence\n",
    "- Adjust frame rate\n",
    "- Add motion blur for smoother playback\n",
    "\n",
    "### ⚙️ Tuning Parameters\n",
    "\n",
    "If you need to adjust the alignment quality, modify these parameters in the configuration section:\n",
    "\n",
    "- **`zoom_factor`**: Increase (1.2-1.3) for more aggressive border cropping\n",
    "- **`max_features`**: Increase (7000-10000) for better feature detection\n",
    "- **`min_matches`**: Decrease (5-8) for difficult scenes, increase (15-20) for stricter quality\n",
    "\n",
    "### 📊 Quality Tips\n",
    "\n",
    "1. **Consistent Lighting**: Take photos at the same time of day\n",
    "2. **Stable Position**: Use a tripod or consistent hand position\n",
    "3. **Regular Intervals**: Consistent time gaps between photos\n",
    "4. **Weather Consideration**: Avoid windy days for outdoor subjects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
